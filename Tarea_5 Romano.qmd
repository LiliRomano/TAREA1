---
title: "Tarea 5. Diferenciación e integración numérica."
author: "ROMANO"
format: 
  html:
    grid: 
      body-width: 1000px
editor: visual
jupyter: python3
---

Importamos packages y funciones necesarias:

```{python}
#| code-fold: true

import matplotlib.pyplot as plt
import numpy as np
import math
from scipy.interpolate import lagrange
from numpy.polynomial.polynomial import Polynomial
from scipy.interpolate import CubicSpline

import plotly.graph_objects as go
from scipy.differentiate import derivative
import numdifftools as nd
from scipy.stats import norm
from scipy import integrate
from scipy.stats import beta 
from scipy.integrate import quadv

```

# Ejercicio 1.

Para cada una de las siguientes funciones:

-   Realiza la respectiva gráfica en el intervalo dado.

-   Compara las gráficas de las derivadas aproximadas de la función `derivative` de `Scipy`, con dos tamaños de paso utilizando la función `nd.Derivative` y la derivada *exacta* en tal intervalo.

-   Compara las gráficas de las segundas derivadas aproximadas con dos tamaños de paso utilizando la función `nd.Derivative` y la segunda derivada *exacta* en tal intervalo.

-   Realiza las gráficas de los errores absolutos en cada caso.

a)  $f(x)=e^{2x}-cos 2x$, $x\in [0,2]$
:::

```{python}
#| code-fold: true
#| fig-align: 'center'


f = lambda x: np.exp(2*x)-np.cos(2*x)

x_values = np.linspace(0, 2, 200)

plt.figure(figsize=(7,3))
plt.plot(x_values,  f(x_values), color = "indigo", linewidth=1.7)
plt.grid()
plt.show()
```

Derivada : $f'(x)= 2e^{2x}+2sin(2x)$. Aproximaciones con dos tamaños de paso $h=0.13$ y $h=0.7$


```{python}
import numpy as np
import matplotlib.pyplot as plt
from scipy.misc import derivative
from numdifftools import Derivative as nd_Derivative

# Definimos la función y su derivada exacta
def f(x):
    return np.exp(2*x) - np.cos(2*x)

def f_prime_exact(x):
    return 2*np.exp(2*x) + 2*np.sin(2*x)

# Intervalo de evaluación
x = np.linspace(0, 2, 200)

# Valores exactos
y = f(x)
y_prime_exact = f_prime_exact(x)

# Tamaños de paso específicos para este ejercicio
h1 = 0.13  # primer tamaño de paso
h2 = 0.7   # segundo tamaño de paso (más grande)

# Derivadas aproximadas con scipy.misc.derivative
y_prime_h1 = [derivative(f, xi, dx=h1, n=1) for xi in x]
y_prime_h2 = [derivative(f, xi, dx=h2, n=1) for xi in x]

# Derivadas con numdifftools
nd_prime_h1 = nd_Derivative(f, step=h1)(x)
nd_prime_h2 = nd_Derivative(f, step=h2)(x)

# Cálculo de errores absolutos
error_prime_h1 = np.abs(y_prime_exact - y_prime_h1)
error_prime_h2 = np.abs(y_prime_exact - y_prime_h2)
error_nd_prime_h1 = np.abs(y_prime_exact - nd_prime_h1)
error_nd_prime_h2 = np.abs(y_prime_exact - nd_prime_h2)

# Configuración de gráficos
plt.figure(figsize=(14, 8))

# Gráfica de la función original
plt.subplot(2, 2, 1)
plt.plot(x, y, label='f(x) = e^(2x) - cos(2x)')
plt.title('Función original')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid()
plt.legend()

# Gráficas de derivadas
plt.subplot(2, 2, 2)
plt.plot(x, y_prime_exact, 'k-', linewidth=2, label='Derivada exacta')
plt.plot(x, y_prime_h1, 'r--', label=f'scipy h={h1}')
plt.plot(x, y_prime_h2, 'b--', label=f'scipy h={h2}')
plt.plot(x, nd_prime_h1, 'g:', label=f'nd h={h1}')
plt.plot(x, nd_prime_h2, 'm:', label=f'nd h={h2}')
plt.title(f"Comparación de derivadas\nf'(x) = 2e^(2x) + 2sin(2x)")
plt.xlabel('x')
plt.ylabel("f'(x)")
plt.grid()
plt.legend()

# Gráficas de errores (scipy)
plt.subplot(2, 2, 3)
plt.plot(x, error_prime_h1, 'r--', label=f'scipy h={h1}')
plt.plot(x, error_prime_h2, 'b--', label=f'scipy h={h2}')
plt.title('Errores absolutos (scipy.misc.derivative)')
plt.xlabel('x')
plt.ylabel('Error absoluto')
plt.yscale('log')
plt.grid()
plt.legend()

# Gráficas de errores (numdifftools)
plt.subplot(2, 2, 4)
plt.plot(x, error_nd_prime_h1, 'g:', label=f'nd h={h1}')
plt.plot(x, error_nd_prime_h2, 'm:', label=f'nd h={h2}')
plt.title('Errores absolutos (numdifftools.Derivative)')
plt.xlabel('x')
plt.ylabel('Error absoluto')
plt.yscale('log')
plt.grid()
plt.legend()

plt.tight_layout()
plt.show()

# Análisis de errores máximos
print("\nAnálisis de errores máximos:")
print(f"Error máximo scipy h={h1}: {np.max(error_prime_h1):.4e}")
print(f"Error máximo scipy h={h2}: {np.max(error_prime_h2):.4e}")
print(f"Error máximo nd h={h1}: {np.max(error_nd_prime_h1):.4e}")
print(f"Error máximo nd h={h2}: {np.max(error_nd_prime_h2):.4e}")
```

:::
:::
b)  $f(x)=log(x+2)-(x+1)^2$, $x\in [0,5]$
:::
:::
#Grafica del Intervalo

```{python}
#| code-fold: true
#| fig-align: 'center'

f= lambda x: np.log(x+2)-(x+1)**2
derf = lambda x: 1/(x+2)-2*(x+1)

x_values = np.linspace(0, 5, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,  f(x_values))

plt.grid()
plt.show()
```

#Aproximación

```{python}
#| code-fold: true
#| fig-align: 'center'

# Función de numdifftools
df_01 = nd.Derivative(f, step=0.1, method='central', order=2)
df_025 = nd.Derivative(f, step=0.25, method='central', order=2)

fig = go.Figure()
fig.add_trace(go.Scatter(x= x_values, y= derf(x_values), mode='lines', name='Derivada', line=dict(color='goldenrod', width=3)))
fig.add_trace(go.Scatter(x= x_values, y= df_01(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= df_025(x_values), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))

fig.add_trace(go.Scatter(x= x_values, y= derivative(f, x_values).df, mode='lines', name='SciPy', line=dict(color='aqua', width=2)))


# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de las derivadas",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

#Errores

```{python}
#| code-fold: true

fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_025(x_values)), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_01(x_values)), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-derivative(f, x_values).df), mode='lines', name='SciPy', line=dict(color='aqua', width=2)))


# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de errores",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

**Primera Derivada**

Derivada : $f'(x)= -2x+\frac{1}{x+2}-2$. Aproximaciones con dos tamaños de paso $h=0.25$ y $h=0.1$

```{python}
#| code-fold: true
#| warning: false
#| message: false

derf = lambda x: -2*x + ((1)/(x+2)) -2


df_1 = nd.Derivative(f, step=0.1, method='central', order=2)
df_25 = nd.Derivative(f, step=0.25, method='central', order=2)


fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= df_1(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= df_25(x_values), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))

fig.add_trace(go.Scatter(x= x_values, y= derivative(f, x_values).df, mode='lines', name='SciPy', line=dict(color='aqua', width=2)))

fig.add_trace(go.Scatter(x= x_values, y= derf(x_values), mode='lines', name='Derivada', line=dict(color='goldenrod', width=1)))

fig.update_layout(
    title="Gráfica de aproximación de las derivadas",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```


#Aproximación 2da Derivada

```{python}
#| code-fold: true


dderf  = lambda x: -1/(x+2)**2-2

a = 0 
b= 5

ddf_01 = nd.Derivative(f, step=0.1, method='central', order=2, n = 2)
ddf_025 = nd.Derivative(f, step=0.25, method='central', order=2, n = 2)
fig = go.Figure()

x_values = np.linspace(a, b, 500)

fig.add_trace(go.Scatter(x= x_values, y= ddf_025(x_values), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= ddf_01(x_values), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= dderf(x_values), mode='lines', name='2da. derivada', line=dict(color='goldenrod', width=1)))

# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de la 2da derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

#Errores 2da Derivada

```{python}
#| code-fold: true

fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_025(x_values)), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_01(x_values)), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))


# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de errores 2da. derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

:::
:::

c)  $f(x)=\sqrt{x} sen(x^2)$, $x\in [0,\pi]$

Gráfica de la función.

```{python}
#| code-fold: true
#| fig-align: 'center'


f = lambda x: np.sqrt(x)*np.sin(x**2)

x_values = np.linspace(0, np.pi, 200)

plt.figure(figsize=(8,6))
plt.plot(x_values,  f(x_values), color = "indigo", linewidth=1.7)
plt.grid()
plt.show()
```

Derivada : $f'(x)= 2x\sqrt{x}\,cos(x^2)+\frac{sen(x^2)}{2\sqrt{x}}$. Aproximaciones con dos tamaños de paso $h=0.05$ y $h=0.1$

```{python}
#| code-fold: true
#| warning: false
#| message: false

derf = lambda x: 2* x * np.sqrt(x) * np.cos(x**2)+ (np.sin(x**2)/2) * (1/np.sqrt(x))

# Función de numdifftools
df_01 = nd.Derivative(f, step=0.1, method='central', order=2)
df_005 = nd.Derivative(f, step=0.05, method='central', order=2)


fig = go.Figure()
# Aproximación de la derivada con los tamaños de paso 
fig.add_trace(go.Scatter(x= x_values, y= df_01(x_values), mode='lines', name='h=0.1', line=dict(color='blue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= df_005(x_values), mode='lines', name='h=0.05', line=dict(color='royalblue', width=1)))
# Aproximación de la derivada con derivative de Scipy
fig.add_trace(go.Scatter(x= x_values, y= derivative(f, x_values).df, mode='lines', name='SciPy', line=dict(color='aqua', width=2)))
# Derivada "exacta"
fig.add_trace(go.Scatter(x= x_values, y= derf(x_values), mode='lines', name='Derivada', line=dict(color='goldenrod', width=1)))

fig.update_layout(
    title="Gráfica de aproximación de las derivadas",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Gráfica del valor absoluto de los errores para las aproximaciones de la primera derivada.

```{python}
#| code-fold: true
#| warning: false


fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_01(x_values)), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_005(x_values)), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-derivative(f, x_values).df), mode='lines', name='SciPy', line=dict(color='aqua', width=2)))

fig.update_layout(
    title="Gráfica de errores",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

Segunda derivada: $f''(x)= 4 \sqrt{x}\, cos(x^2)-sen(x^2)\left(4 x^2 \sqrt{x}+\frac{1}{4x\sqrt{x}} \right)$. Aproximaciones con $h=0.05$ y $h=0.1$

```{python}
#| code-fold: true
#| warning: false

dderf = lambda x: 4* np.sqrt(x) * np.cos(x**2) -np.sin(x**2) *(4* x**2 * np.sqrt(x)+1/(4*x*np.sqrt(x)))

# Funciones de numdifftools para la segunda derivada
ddf_01 = nd.Derivative(f, step=0.1, method='central', order=2, n = 2)
ddf_005 = nd.Derivative(f, step=0.05, method='central', order=2, n = 2)

fig = go.Figure()
fig.add_trace(go.Scatter(x= x_values, y= ddf_01(x_values), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= ddf_005(x_values), mode='lines', name='h=0.05', line=dict(color='red', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= dderf(x_values), mode='lines', name='2da. derivada', line=dict(color='goldenrod', width=1)))

# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de la 2da derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()

```

Gráfica del valor absoluto de los errores para las aproximaciones de la segunda derivada.

```{python}
#| code-fold: true
#| warning: false


fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_01(x_values)), mode='lines', name='h=0.1', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_005(x_values)), mode='lines', name='h=0.05', line=dict(color='teal', width=1)))

fig.update_layout(
    title="Gráfica de errores segunda derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

:::
:::
d)  $f(x)=(cos\,3x)^2-e^{2x}$, $x\in [0,\pi/2]$


#Grafica del Intervalo

```{python}

#| code-fold: true
#| fig-align: 'center'

f= lambda x: (np.cos(3*x))**2 - np.exp(2*x)
derf = lambda x: -6*np.cos(3*x)*np.sin(3*x) - 2*np.exp(2*x)

x_values = np.linspace(0, np.pi/2, 500)

plt.figure(figsize=(9,5))
plt.plot(x_values,  f(x_values))

plt.grid()
plt.show()
```

#Aproximación

```{python}
#| code-fold: true
#| fig-align: 'center'

# Función de numdifftools
df_01 = nd.Derivative(f, step=0.1, method='central', order=2)
df_025 = nd.Derivative(f, step=0.25, method='central', order=2)

fig = go.Figure()
fig.add_trace(go.Scatter(x= x_values, y= derf(x_values), mode='lines', name='Derivada', line=dict(color='goldenrod', width=3)))
fig.add_trace(go.Scatter(x= x_values, y= df_01(x_values), mode='lines', name='h=0.1', line=dict(color='red', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= df_025(x_values), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))

fig.add_trace(go.Scatter(x= x_values, y= derivative(f, x_values).df, mode='lines', name='SciPy', line=dict(color='aqua', width=2)))


# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de las derivadas",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```


#Errores

```{python}
#| code-fold: true
#| message: false 
#| warning: false
fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_025(x_values)), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-df_01(x_values)), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(derf(x_values)-derivative(f, x_values).df), mode='lines', name='SciPy', line=dict(color='aqua', width=2)))


# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de errores",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

#Aproximación 2da Derivada


```{python}
#| code-fold: true


#dderf  = lambda x: -18*np.cos(6*x) - 4*np.exp(2*x)

a = 0 
b= np.pi

ddf_01 = nd.Derivative(f, step=0.1, method='central', order=2, n = 2)
ddf_025 = nd.Derivative(f, step=0.25, method='central', order=2, n = 2)
fig = go.Figure()

x_values = np.linspace(a, b, 500)

fig.add_trace(go.Scatter(x= x_values, y= ddf_025(x_values), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= ddf_01(x_values), mode='lines', name='h=0.1', line=dict(color='indigo', width=1)))
#fig.add_trace(go.Scatter(x= x_values, y= dderf(x_values), mode='lines', name='2da. derivada', line=dict(color='goldenrod', width=1)))

# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de aproximación de la 2da derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```

#Errores 2da Derivada

```{python}
#| code-fold: true

fig = go.Figure()

fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_025(x_values)), mode='lines', name='h=0.25', line=dict(color='royalblue', width=1)))
fig.add_trace(go.Scatter(x= x_values, y= abs(dderf(x_values)-ddf_01(x_values)), mode='lines', name='h=0.1', line=dict(color='teal', width=1)))


# Configurar diseño de la gráfica
fig.update_layout(
    title="Gráfica de errores 2da. derivada",
    xaxis_title="x",
    yaxis_title="y",
    template="plotly_white",
    width = 768,
    height = 576
)

fig.show()
```
:::
:::
# Ejericicio 2

Aproximar las siguientes integrales con la función `integrate.quad` (de SciPy) y con el método de Montecarlo, en cada caso hacer una gráfica de la función e indicar el área bajo la curva.

a)  

\begin{equation}
\int_0^1 e^{-x^2}\,dx
\end{equation}

Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'

f= lambda x: np.exp(-x**2)
  
a = 0
b = 1

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función", color="black")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="turquoise", alpha=0.5)
plt.grid()
plt.legend()
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N = 10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = np.abs(y) <= abs(f(x))
puntos_in = puntos_in * np.sign(y)== np.sign(f(x))
puntos_in_positivo = puntos_in *(1 == np.sign(f(x)))
puntos_in_negativo = puntos_in *(0 == np.sign(f(x)))

puntos_out = ~ puntos_in
puntos_out_positivo = puntos_out * (1 == np.sign(y))
puntos_out_negativo = puntos_out * (0 == np.sign(y))



x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))

plt.plot(x[puntos_in_positivo], y[puntos_in_positivo], 'o', color="red", label= "Puntos in +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_in_negativo], y[puntos_in_negativo], 'o', color="black", label= "Puntos in -", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_positivo], y[puntos_out_positivo], 'o', color="blush", label= "Puntos out +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_negativo], y[puntos_out_negativo], 'o', color="skyblue", label= "Puntos out -", alpha=0.5, markersize=2.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in_positivo)/(sum(puntos_in_positivo) + sum(puntos_out_positivo))) 

print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

b)  

\begin{equation}
\int_0^\pi sen(x^2)\,dx
\end{equation}

Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'

f= lambda x: np.sin(x ** 2)
  
a = 0
b = np.pi

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(9,5))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="indigo", alpha=0.5)
plt.grid()
plt.legend()
#plt.axis('square')
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =500000

ymax = 1
ymin = -1

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = np.abs(y) <= abs(f(x))
puntos_in = puntos_in * np.sign(y)== np.sign(f(x))
puntos_in_positivo = puntos_in *(1 == np.sign(f(x)))
puntos_in_negativo = puntos_in *(-1 == np.sign(f(x)))

puntos_out = ~ puntos_in
puntos_out_positivo = puntos_out * (1 == np.sign(y))
puntos_out_negativo = puntos_out * (-1 == np.sign(y))



x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))

plt.plot(x[puntos_in_positivo], y[puntos_in_positivo], 'o', color="indigo", label= "Puntos in +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_in_negativo], y[puntos_in_negativo], 'o', color="red", label= "Puntos in -", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_positivo], y[puntos_out_positivo], 'o', color="blue", label= "Puntos out +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_negativo], y[puntos_out_negativo], 'o', color="green", label= "Puntos out -", alpha=0.5, markersize=2.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.7)
plt.grid()
plt.legend()
plt.show()

  
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in_positivo)/(sum(puntos_in_positivo) + sum(puntos_out_positivo))) + (b-a) * ymin * (sum(puntos_in_negativo)/(sum(puntos_in_negativo) + sum(puntos_out_negativo))) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

c)  

\begin{equation}
\int_0^\pi \frac{sen(x)}{x}\,dx
\end{equation}

Gráfica de la función y área bajo la curva.

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: np.sin(x)/x
  
a = 0
b = np.pi


x_values = np.linspace(a, b, 100)


plt.figure(figsize=(9,5))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="aquamarine", alpha=0.5)
plt.grid()
plt.legend()
#plt.axis('square')
plt.show()
```


**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)
  
x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="indigo", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.7)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

d)  

\begin{equation}
\int_0^\infty e^{-x^2} cos(x) \,dx
\end{equation}

Gráfica de la función y *área bajo la curva.*

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: np.exp(-x**2)*np.cos(x)
  
a = 0
b = 10 #Remplazamos np.inf por un número finito para poder graficar


x_values = np.linspace(a, b, 1000)


plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función", color="black")
plt.fill_between(np.linspace(a,b, 1000), y1=0, y2=f(np.linspace(a,b, 1000)), color="blue", alpha=0.5)
plt.grid()
plt.legend()
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, np.inf)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =100000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = np.abs(y) <= abs(f(x))
puntos_in = puntos_in * np.sign(y)== np.sign(f(x))
puntos_in_positivo = puntos_in *(1 == np.sign(f(x)))
puntos_in_negativo = puntos_in *(0 == np.sign(f(x)))

puntos_out = ~ puntos_in
puntos_out_positivo = puntos_out * (1 == np.sign(y))
puntos_out_negativo = puntos_out * (0 == np.sign(y))



x_values = np.linspace(a, b, 1000)

plt.figure(figsize=(8,6))

plt.plot(x[puntos_in_positivo], y[puntos_in_positivo], 'o', color="blue", label= "Puntos in +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_in_negativo], y[puntos_in_negativo], 'o', color="red", label= "Puntos in -", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_positivo], y[puntos_out_positivo], 'o', color="indigo", label= "Puntos out +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_negativo], y[puntos_out_negativo], 'o', color="black", label= "Puntos out -", alpha=0.5, markersize=2.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```


e)  

\begin{equation}
\int_0^1 x^x \,dx
\end{equation}

Gráfica de la función y *área bajo la curva*.

```{python}
#| code-fold: true
#| fig-align: 'center'
f= lambda x: x**x
  
a = 0
b = 1

x_values = np.linspace(a, b, 100)
plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función", color="indigo")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="red", alpha=0.5)
plt.grid()
plt.legend()
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true
integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =100000

ymax = 1
ymin = -1

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = np.abs(y) <= abs(f(x))
puntos_in = puntos_in * np.sign(y)== np.sign(f(x))
puntos_in_positivo = puntos_in *(1 == np.sign(f(x)))
puntos_in_negativo = puntos_in *(-1 == np.sign(f(x)))

puntos_out = ~ puntos_in
puntos_out_positivo = puntos_out * (1 == np.sign(y))
puntos_out_negativo = puntos_out * (-1 == np.sign(y))

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(9,5))

plt.plot(x[puntos_in_positivo], y[puntos_in_positivo], 'o', color="indigo", label= "Puntos in +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_in_negativo], y[puntos_in_negativo], 'o', color="black", label= "Puntos in -", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_positivo], y[puntos_out_positivo], 'o', color="blue", label= "Puntos out +", alpha=0.5, markersize=2.5)
plt.plot(x[puntos_out_negativo], y[puntos_out_negativo], 'o', color="green", label= "Puntos out -", alpha=0.5, markersize=2.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```



f)  

\begin{equation}
\int_1^5 e^{-x^2} x^3 dx
\end{equation}


```{python}
import numpy as np
import matplotlib.pyplot as plt
from scipy import integrate

# Definimos la función
f = lambda x: np.exp(-x**2) * x**3

# Límites de integración
a = 1
b = 5

# Gráfica de la función y área bajo la curva
x_values = np.linspace(a, b, 100)

plt.figure(figsize=(10, 6))
plt.plot(x_values, f(x_values), label="Función f(x) = e^(-x²) * x³", color="orange")
plt.fill_between(x_values, y1=0, y2=f(x_values), color="indigo", alpha=0.5)
plt.title("Gráfica de la función y área bajo la curva")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid()
plt.legend()
plt.show()

# Aproximación de la integral con scipy.integrate.quad
integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]:.6f}, con un error aproximado de {integral[1]:.6e}')

# Aproximación de la integral por el método de Montecarlo
N = 100000

# Determinamos ymax para el rectángulo de Montecarlo
# Evaluamos la función en varios puntos para encontrar el máximo
test_points = np.linspace(a, b, 1000)
ymax = max(f(test_points)) * 1.05  
ymin = 0

# Generación de puntos aleatorios
x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

# Identificación de puntos dentro del área
puntos_in = y <= f(x)

# Gráfica del método de Montecarlo
plt.figure(figsize=(10, 6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="indigo", label="Puntos dentro", alpha=0.3)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label="Puntos fuera", alpha=0.1)
plt.plot(x_values, f(x_values), color="black", label="Función", linewidth=1.5)
plt.title("Método de Montecarlo para aproximación de la integral")
plt.xlabel("x")
plt.ylabel("f(x)")
plt.grid()
plt.legend()
plt.show()

# Cálculo de la integral por Montecarlo
integral_montecarlo = (b - a) * (ymax - ymin) * (sum(puntos_in) / N)

print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo:.6f}')
print(f'Altura del rectángulo de Montecarlo (ymax): {ymax:.4f}')
```


g)  

\begin{equation}
\int_0^1 \sqrt{1-x^2} dx
\end{equation}

Gráfica de la función y área bajo la curva

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: np.sqrt(1-x**2)
  
a = 0
b = 1

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(8,6))
plt.plot(x_values,f(x_values), label="Función")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="indigo", alpha=0.5)
plt.grid()
plt.legend()
plt.axis('square')
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="indigo", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.axis('square')
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```

h)  

\begin{equation}
\int_0^\infty \frac{x}{e^x-1} dx
\end{equation}

```{python}
# Definimos la función
f = lambda x: x / (np.exp(x) - 1)

# Límites de integración (usamos un límite superior grande en lugar de infinito)
a = 0
b = 100  # Suficientemente grande para aproximar el infinito

# Gráfica de la función y área bajo la curva
x_values = np.linspace(a, b, 1000)

plt.figure(figsize=(10, 6))
plt.plot(x_values, f(x_values), label="Función", color="black")
plt.fill_between(x_values, y1=0, y2=f(x_values), color="indigo", alpha=0.5)
plt.title(r'Gráfica de $f(x) = \frac{x}{e^x - 1}$ y área bajo la curva')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid()
plt.legend()
plt.xlim(0, 10)  # Mostramos solo hasta x=10 para mejor visualización
plt.show()

# Aproximación de la integral con scipy.integrate.quad
integral_quad, error = integrate.quad(f, a, np.inf)  # Podemos usar np.inf directamente

print(f'Aproximación de la integral con quad: {integral_quad:.6f}')
print(f'Error estimado: {error:.2e}')

# Aproximación por el método de Montecarlo
N = 100000  
ymax = 1.0   
ymin = 0

# Generamos puntos aleatorios en [a,b]×[ymin,ymax]
x_rand = np.random.uniform(a, b, N)
y_rand = np.random.uniform(ymin, ymax, N)

# Identificamos puntos bajo la curva
puntos_dentro = y_rand <= f(x_rand)

# Gráfica de Montecarlo
plt.figure(figsize=(10, 6))
plt.plot(x_rand[puntos_dentro], y_rand[puntos_dentro], 'o', 
         color="green", label="Puntos dentro", alpha=0.3, markersize=2)
plt.plot(x_rand[~puntos_dentro], y_rand[~puntos_dentro], 'o', 
         color="blue", label="Puntos fuera", alpha=0.3, markersize=2)
plt.plot(x_values, f(x_values), color="black", label="Función", linewidth=1.5)
plt.title('Aproximación de Montecarlo')
plt.xlabel('x')
plt.ylabel('f(x)')
plt.grid()
plt.legend()
plt.xlim(0, 10)  # Mostramos solo hasta x=10 para mejor visualización
plt.show()

# Cálculo de la integral por Montecarlo
area_total = (b - a) * (ymax - ymin)
integral_montecarlo = area_total * (np.sum(puntos_dentro) / N

print(f'Aproximación con Montecarlo (N={N}): {integral_montecarlo:.6f}')
print(f'Valor teórico conocido: π²/6 ≈ {np.pi**2/6:.6f}')
```

i)  

\begin{equation}
\int_0^1 \frac{1}{\sqrt{x^4+1}} dx
\end{equation}

```{python}
Gráfica de la función y *área bajo la curva.*

```{python}
#| code-fold: true
#| fig-align: 'center'
#| warning: false

f= lambda x: 1/(np.sqrt(x**4+1))
  
a = 0
b = 1

x_values = np.linspace(a, b, 100)

plt.figure(figsize=(9,5))
plt.plot(x_values,f(x_values), label="Función", color="black")
plt.fill_between(np.linspace(a,b, 100), y1=0, y2=f(np.linspace(a,b, 100)), color="indigo", alpha=0.5)
plt.grid()
plt.legend()
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

integral = integrate.quad(f, a, b)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

**Aproximación de la integral por el método de Montecarlo.**

```{python}
#| code-fold: true
#| fig-align: 'center'

N =10000

ymax = 1
ymin = 0

x = np.random.uniform(a, b, N)
y = np.random.uniform(ymin, ymax, N)

puntos_in = y <= f(x)

plt.figure(figsize=(8,6))
plt.plot(x[puntos_in], y[puntos_in], 'o', color="indigo", label= "Puntos in", alpha=0.5)
plt.plot(x[~puntos_in], y[~puntos_in], 'o', color="blue", label= "Puntos out", alpha=0.5)
plt.plot(x_values,f(x_values), color= "black", label="Función", linewidth=1.2)
plt.grid()
plt.legend()
plt.show()
```

```{python}
#| code-fold: true

integral_montecarlo = (b-a)* ymax *(sum(puntos_in)/N) 


print(f'El valor aproximado de la integral con el método de Montecarlo es: {integral_montecarlo}')
```
:::
# Ejercicio 3

Aproximar las siguientes integrales dobles y triples, llevar a cabo la gráfica cuando se indique y comparar con el valor *exacto* de la integral.

a)  Realizar gráfica

\begin{equation}
\int_{-1}^{1}\int_1^2 (3y^2-x^2+5) dx dy
\end{equation}

```{python}
# Función a integrar
def f(x, y):
    return 3*y**2 - x**2 + 5

# Límites de integración
x_limits = (1, 2)
y_limits = (-1, 1)

## 1. Solución exacta usando scipy.integrate.dblquad
exact_result, exact_error = integrate.dblquad(f, y_limits[0], y_limits[1], 
                                           lambda x: x_limits[0], lambda x: x_limits[1])

## 2. Método de Montecarlo para integral doble
def monte_carlo_double(f, xlim, ylim, num_samples=100000):
    # Generar puntos aleatorios en el rectángulo [xlim]×[ylim]
    x_random = np.random.uniform(xlim[0], xlim[1], num_samples)
    y_random = np.random.uniform(ylim[0], ylim[1], num_samples)
    
    # Evaluar la función en los puntos aleatorios
    f_values = f(x_random, y_random)
    
    # Calcular el área del rectángulo
    area = (xlim[1] - xlim[0]) * (ylim[1] - ylim[0])
    
    # Estimación de la integral
    mc_result = area * np.mean(f_values)
    
    return mc_result, x_random, y_random, f_values

# Aplicar Montecarlo
num_samples = 1000000
mc_result, x_mc, y_mc, f_mc = monte_carlo_double(f, x_limits, y_limits, num_samples)

## Visualización 3D de la función
x = np.linspace(x_limits[0], x_limits[1], 100)
y = np.linspace(y_limits[0], y_limits[1], 100)
X, Y = np.meshgrid(x, y)
Z = f(X, Y)

fig = plt.figure(figsize=(16, 6))

# Gráfico 3D de la superficie
ax1 = fig.add_subplot(121, projection='3d')
surf = ax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)
fig.colorbar(surf, ax=ax1, shrink=0.5, aspect=5)
ax1.set_title('Superficie z = 3y² - x² + 5')
ax1.set_xlabel('x')
ax1.set_ylabel('y')
ax1.set_zlabel('z')

# Gráfico de contorno con puntos de Montecarlo
ax2 = fig.add_subplot(122)
contour = ax2.contourf(X, Y, Z, 20, cmap='viridis')
ax2.scatter(x_mc[:5000], y_mc[:5000], c=f_mc[:5000], 
           s=1, alpha=0.1, cmap='viridis')  # Mostrar solo 5000 puntos para claridad
fig.colorbar(contour, ax=ax2, shrink=0.5, aspect=5)
ax2.set_title('Mapa de contorno con puntos de Montecarlo')
ax2.set_xlabel('x')
ax2.set_ylabel('y')
ax2.set_xlim(x_limits)
ax2.set_ylim(y_limits)

plt.tight_layout()
plt.show()

## Resultados y comparación
# Cálculo del valor exacto analítico (integrando manualmente)
# ∫∫ (3y² - x² + 5) dx dy = ∫ [3y²x - x³/3 + 5x]₁² dy = ∫ (3y²(2-1) - (8-1)/3 + 5(2-1)) dy
# = ∫ (3y² - 7/3 + 5) dy = ∫ (3y² + 8/3) dy = [y³ + (8/3)y]₋₁¹ = (1 + 8/3) - (-1 - 8/3) = 2 + 16/3 = 22/3 ≈ 7.333...

exact_analytic = 22/3

print(f"Resultado exacto (analítico): {exact_analytic:.8f}")
print(f"Resultado con scipy.integrate.dblquad: {exact_result:.8f} (error estimado: {exact_error:.2e})")
print(f"Resultado con Montecarlo ({num_samples:,} muestras): {mc_result:.8f}")
print(f"\nDiferencias:")
print(f"Analítico vs dblquad: {abs(exact_analytic - exact_result):.2e}")
print(f"Analítico vs Montecarlo: {abs(exact_analytic - mc_result):.2e}")
print(f"dblquad vs Montecarlo: {abs(exact_result - mc_result):.2e}")
```

b)  

\begin{equation}
\int_{0}^{6}\int_1^5 \sqrt{x+4y} dx dy
\end{equation}

```{python}
# Función a integrar
def f(x, y):
    return np.sqrt(x + 4*y)

# Límites de integración
x_limits = (1, 5)
y_limits = (0, 6)

## 1. Solución exacta usando scipy.integrate.dblquad
exact_result, exact_error = integrate.dblquad(f, y_limits[0], y_limits[1], 
                                         lambda y: x_limits[0], lambda y: x_limits[1])

## 2. Método de Montecarlo para integral doble
def monte_carlo_double_integration(f, xlim, ylim, num_samples=1000000):
    # Generar puntos aleatorios uniformemente distribuidos
    x_random = np.random.uniform(xlim[0], xlim[1], num_samples)
    y_random = np.random.uniform(ylim[0], ylim[1], num_samples)
    
    # Evaluar la función en los puntos aleatorios
    f_values = f(x_random, y_random)
    
    # Calcular el área del dominio rectangular
    area = (xlim[1] - xlim[0]) * (ylim[1] - ylim[0])
    
    # Estimación de la integral
    mc_result = area * np.mean(f_values)
    
    return mc_result, x_random, y_random, f_values

# Aplicar Montecarlo
num_samples = 1000000
mc_result, x_mc, y_mc, f_mc = monte_carlo_double_integration(f, x_limits, y_limits, num_samples)

## Visualización 3D de la función
x = np.linspace(x_limits[0], x_limits[1], 100)
y = np.linspace(y_limits[0], y_limits[1], 100)
X, Y = np.meshgrid(x, y)
Z = f(X, Y)

fig = plt.figure(figsize=(16, 6))

# Gráfico 3D de la superficie
ax1 = fig.add_subplot(121, projection='3d')
surf = ax1.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)
ax1.set_title('Superficie z = √(x + 4y)')
ax1.set_xlabel('x')
ax1.set_ylabel('y')
ax1.set_zlabel('z')
fig.colorbar(surf, ax=ax1, shrink=0.5, aspect=5)

# Gráfico de contorno con puntos de Montecarlo
ax2 = fig.add_subplot(122)
contour = ax2.contourf(X, Y, Z, levels=20, cmap='viridis')
ax2.scatter(x_mc[:5000], y_mc[:5000], c='r', s=1, alpha=0.1)  # Mostrar solo 5000 puntos para claridad
ax2.set_title('Mapa de contorno con puntos de Montecarlo')
ax2.set_xlabel('x')
ax2.set_ylabel('y')
plt.colorbar(contour, ax=ax2, shrink=0.5, aspect=5)

plt.tight_layout()
plt.show()

## Resultados
print(f"Resultado exacto (dblquad): {exact_result:.8f} (error estimado: {exact_error:.2e})")
print(f"Resultado con Montecarlo ({num_samples:,} muestras): {mc_result:.8f}")
print(f"Diferencia entre métodos: {abs(exact_result - mc_result):.2e}")

# Valor exacto calculado analíticamente
def exact_integral():
    def x_integral(y):
        return (2/3) * ((5 + 4*y)**(3/2) - (1 + 4*y)**(3/2))
    result, _ = integrate.quad(x_integral, 0, 6)
    return result

exact_analytic = exact_integral()
print(f"\nValor exacto calculado analíticamente: {exact_analytic:.8f}")
print(f"Diferencia con dblquad: {abs(exact_analytic - exact_result):.2e}")
print(f"Diferencia con Montecarlo: {abs(exact_analytic - mc_result):.2e}")
```


c)  

\begin{equation}
\int_{1}^{e}\int_0^{log(x)} x^3 dx dy
\end{equation}

```{python}
# Función a integrar
def f(x, y):
    return x**3

# Límites de integración
x_limits = (1, np.e)
y_limits = lambda x: (0, np.log(x))

## 1. Solución exacta usando scipy.integrate.dblquad
exact_result, exact_error = integrate.dblquad(f, x_limits[0], x_limits[1],
                                           lambda x: y_limits(x)[0],
                                           lambda x: y_limits(x)[1])

## 2. Método de Montecarlo para integral doble con dominio variable
def monte_carlo_double_integration(f, xlim, ylim_func, num_samples=1000000):
    # Primero muestreamos en x uniformemente
    x_random = np.random.uniform(xlim[0], xlim[1], num_samples)
    
    # Para cada x, muestreamos y en [0, log(x)]
    y_random = np.array([np.random.uniform(0, ylim_func(x)[1]) for x in x_random])
    
    # Evaluar la función en los puntos aleatorios
    f_values = f(x_random, y_random)
    
    # Calcular el jacobiano del cambio de variable
    jacobian = ylim_func(x_random)[1]  # altura en cada x
    
    # Estimación de la integral
    mc_result = (xlim[1] - xlim[0]) * np.mean(f_values * jacobian)
    
    return mc_result, x_random, y_random

# Aplicar Montecarlo
num_samples = 1000000
mc_result, x_mc, y_mc = monte_carlo_double_integration(f, x_limits, y_limits, num_samples)

## Visualización del dominio de integración
x = np.linspace(x_limits[0], x_limits[1], 500)
y_upper = np.log(x)

fig, ax = plt.subplots(figsize=(10, 6))

# Dibujar el dominio de integración
ax.fill_between(x, y_upper, color='skyblue', alpha=0.3, label='Dominio de integración')
ax.plot(x, y_upper, 'b-', label='y = log(x)')

# Dibujar algunos puntos de Montecarlo
ax.scatter(x_mc[:5000], y_mc[:5000], color='red', s=1, alpha=0.3, label='Puntos Montecarlo')

ax.set_xlim(x_limits[0], x_limits[1])
ax.set_ylim(0, np.log(x_limits[1])*1.1)
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_title('Dominio de integración y puntos de Montecarlo')
ax.legend()
ax.grid(True)

plt.tight_layout()
plt.show()

## Resultados numéricos
print(f"Resultado exacto (dblquad): {exact_result:.8f} (error estimado: {exact_error:.2e})")
print(f"Resultado con Montecarlo ({num_samples:,} muestras): {mc_result:.8f}")
print(f"Diferencia entre métodos: {abs(exact_result - mc_result):.2e}")

# Valor exacto calculado analíticamente
def exact_integral():
    def integrand(x):
        return (x**4)/4 * np.log(x) - (x**4)/16
    
    exact_analytic = integrand(np.e) - integrand(1)
    return exact_analytic

exact_analytic = exact_integral()
print(f"\nValor exacto calculado analíticamente: {exact_analytic:.8f}")
print(f"Diferencia con dblquad: {abs(exact_analytic - exact_result):.2e}")
print(f"Diferencia con Montecarlo: {abs(exact_analytic - mc_result):.2e}")
```


d)  

\begin{equation}
\int\int_D 30ye^x dx dy
\end{equation}

Donde $D\subset \mathbb{R}^2$ es la región en la siguiente gráfica.

```{python}
#| code-fold: true
#| fig-align: 'center'

x_val = np.array([0,4])
y_val1 = np.array([0, 1])
y_val2 = np.array([0, 4])

plt.figure(figsize=(9,5))
plt.plot(x_val, y_val1)
plt.plot(x_val, y_val2)
plt.fill_between(x_val, y1=y_val1, y2=y_val2, color="indigo", alpha=0.5)
plt.grid()
plt.show()
```

**Aproximación de la integral.**

```{python}
#| code-fold: true

f = lambda y, x: 30 * y * np.exp(x)

integral = integrate.dblquad(f, 0, 4, lambda x: x/4, lambda x: x)
print(f'La aproximación de la integral es: {integral[0]}, con un error aproximado de {integral[1]}')
```

En este caso el valor exacto de la integral es $\frac{225}{8} (5e^4-1)$. Se calcula el error absoluto.

```{python}
#| code-fold: true

integral_exacta = 225/8*(5*np.exp(4)-1)
error_absoluto = abs(integral_exacta - integral[0])
print(f'El error absoluto es:{error_absoluto}')
```

e)  

\begin{equation}
\int\int \int_B z e^{x+y} dx\, dy\, dz, \, B=[0,1] \times [0,1] \times [0,1]
\end{equation}

```{python}
import numpy as np
import matplotlib.pyplot as plt
from scipy import integrate
from mpl_toolkits.mplot3d import Axes3D

# Función a integrar
def f(x, y, z):
    return z * np.exp(x + y)

# Límites de integración (cubo unitario)
limits = [(0, 1), (0, 1), (0, 1)]

## 1. Solución exacta usando scipy.integrate.tplquad
def exact_integral():
    # Podemos resolver analíticamente por separado
    # ∫∫∫ z e^(x+y) dz dy dx = ∫e^x dx ∫e^y dy ∫z dz
    int_x = np.exp(1) - 1
    int_y = np.exp(1) - 1
    int_z = 0.5
    return int_x * int_y * int_z

exact_analytic = exact_integral()

# Solución numérica con tplquad
def integrand(z, y, x):
    return f(x, y, z)

exact_result, exact_error = integrate.tplquad(integrand, 
                                           limits[0][0], limits[0][1],  # x
                                           lambda x: limits[1][0], lambda x: limits[1][1],  # y
                                           lambda x, y: limits[2][0], lambda x, y: limits[2][1])  # z

## 2. Método de Montecarlo para integral triple
def monte_carlo_triple_integration(f, limits, num_samples=1000000):
    # Generar puntos aleatorios uniformemente distribuidos en el cubo
    x = np.random.uniform(limits[0][0], limits[0][1], num_samples)
    y = np.random.uniform(limits[1][0], limits[1][1], num_samples)
    z = np.random.uniform(limits[2][0], limits[2][1], num_samples)
    
    # Evaluar la función en los puntos aleatorios
    f_values = f(x, y, z)
    
    # Calcular el volumen del dominio
    volume = (limits[0][1] - limits[0][0]) * \
             (limits[1][1] - limits[1][0]) * \
             (limits[2][1] - limits[2][0])
    
    # Estimación de la integral
    mc_result = volume * np.mean(f_values)
    
    return mc_result, x, y, z

# Aplicar Montecarlo
num_samples = 1000000
mc_result, x_mc, y_mc, z_mc = monte_carlo_triple_integration(f, limits, num_samples)

## Visualización 3D de puntos de Montecarlo
fig = plt.figure(figsize=(14, 6))

# Gráfico 3D de los puntos
ax1 = fig.add_subplot(121, projection='3d')
scatter = ax1.scatter(x_mc[:5000], y_mc[:5000], z_mc[:5000], 
                     c=f(x_mc[:5000], y_mc[:5000], z_mc[:5000]), 
                     cmap='viridis', s=5, alpha=0.5)
ax1.set_title('Puntos de Montecarlo en el cubo unitario\n(Color por valor de f(x,y,z))')
ax1.set_xlabel('x')
ax1.set_ylabel('y')
ax1.set_zlabel('z')
plt.colorbar(scatter, ax=ax1, label='z e^(x+y)')

# Gráfico de densidad de valores
ax2 = fig.add_subplot(122)
values = f(x_mc, y_mc, z_mc)
ax2.hist(values, bins=50, density=True, color='skyblue', alpha=0.7)
ax2.set_title('Distribución de valores de la función')
ax2.set_xlabel('f(x,y,z)')
ax2.set_ylabel('Densidad')

plt.tight_layout()
plt.show()

## Resultados
print(f"Valor exacto analítico: {exact_analytic:.8f}")
print(f"Resultado numérico (tplquad): {exact_result:.8f} (error estimado: {exact_error:.2e})")
print(f"Resultado con Montecarlo ({num_samples:,} muestras): {mc_result:.8f}")
print(f"\nDiferencias:")
print(f"Analítico vs tplquad: {abs(exact_analytic - exact_result):.2e}")
print(f"Analítico vs Montecarlo: {abs(exact_analytic - mc_result):.2e}")
print(f"tplquad vs Montecarlo: {abs(exact_result - mc_result):.2e}")

# Tasa de convergencia de Montecarlo
sample_sizes = [1000, 10000, 100000, 1000000]
mc_results = []
for size in sample_sizes:
    result, _, _, _ = monte_carlo_triple_integration(f, limits, size)
    mc_results.append(result)

plt.figure(figsize=(8, 5))
plt.loglog(sample_sizes, np.abs(np.array(mc_results) - exact_analytic), 'o-')
plt.xlabel('Número de muestras')
plt.ylabel('Error absoluto')
plt.title('Convergencia del método Montecarlo')
plt.grid(True)
plt.show()
```


f)  

\begin{equation}
\int_0^1 \int_0^x \int_0^y (y+xz) dz\, dy\, dx
\end{equation}

```{python}
import numpy as np
import matplotlib.pyplot as plt
from scipy import integrate
from mpl_toolkits.mplot3d import Axes3D

# Función a integrar
def f(z, y, x):
    return y + x*z

# Límites de integración
x_limits = (0, 1)
y_limits = lambda x: (0, x)
z_limits = lambda x, y: (0, y)

## 1. Solución exacta usando scipy.integrate.tplquad
exact_result, exact_error = integrate.tplquad(f, 
                                           x_limits[0], x_limits[1],
                                           y_limits,
                                           z_limits)

## 2. Método de Montecarlo para integral triple
def monte_carlo_triple_integration(f, xlim, ylim_func, zlim_func, num_samples=1000000):
    # Muestreo uniforme en x
    x_random = np.random.uniform(xlim[0], xlim[1], num_samples)
    
    # Para cada x, muestreo y en [0, x]
    y_random = np.array([np.random.uniform(0, ylim_func(x)[1]) for x in x_random])
    
    # Para cada (x,y), muestreo z en [0, y]
    z_random = np.array([np.random.uniform(0, zlim_func(x, y)[1]) 
                       for x, y in zip(x_random, y_random)])
    
    # Evaluar la función
    f_values = f(z_random, y_random, x_random)
    
    # Calcular los jacobianos
    jacobian_y = ylim_func(x_random)[1]  # y ∈ [0, x]
    jacobian_z = zlim_func(x_random, y_random)[1]  # z ∈ [0, y]
    
    # Estimación de la integral
    mc_result = (xlim[1] - xlim[0]) * np.mean(f_values * jacobian_y * jacobian_z)
    
    return mc_result, x_random, y_random, z_random

# Aplicar Montecarlo
num_samples = 1000000
mc_result, x_mc, y_mc, z_mc = monte_carlo_triple_integration(f, x_limits, y_limits, z_limits, num_samples)

## Visualización del dominio de integración (proyección 3D)
fig = plt.figure(figsize=(14, 6))

# Gráfico 3D del dominio
ax1 = fig.add_subplot(121, projection='3d')
ax1.scatter(x_mc[:5000], y_mc[:5000], z_mc[:5000], c='r', s=1, alpha=0.2)
ax1.set_xlabel('x')
ax1.set_ylabel('y')
ax1.set_zlabel('z')
ax1.set_title('Puntos de Montecarlo en el dominio 3D')

# Gráfico de las relaciones entre variables
ax2 = fig.add_subplot(122)
ax2.scatter(x_mc[:5000], y_mc[:5000], c='b', s=1, alpha=0.1, label='y vs x')
ax2.scatter(y_mc[:5000], z_mc[:5000], c='r', s=1, alpha=0.1, label='z vs y')
ax2.plot([0,1], [0,1], 'k--', label='y = x')
ax2.set_xlabel('Variable independiente')
ax2.set_ylabel('Variable dependiente')
ax2.legend()
ax2.set_title('Relaciones entre variables')
ax2.grid(True)

plt.tight_layout()
plt.show()

## Resultados numéricos
print(f"Resultado exacto (tplquad): {exact_result:.8f} (error estimado: {exact_error:.2e})")
print(f"Resultado con Montecarlo ({num_samples:,} muestras): {mc_result:.8f}")
print(f"Diferencia entre métodos: {abs(exact_result - mc_result):.2e}")

# Valor exacto calculado analíticamente
def exact_integral():
    return 7/60

exact_analytic = exact_integral()
print(f"\nValor exacto calculado analíticamente: {exact_analytic:.8f} (7/60)")
print(f"Diferencia con tplquad: {abs(exact_analytic - exact_result):.2e}")
print(f"Diferencia con Montecarlo: {abs(exact_analytic - mc_result):.2e}")
```

# Ejercicio 4

De [scipy.stats](@https://docs.scipy.org/doc/scipy/reference/stats.html) elige alguna distribución de probabilidad continua, realiza la gráfica y encuentra la probabilidad que la variable aleatoria tome un valor en un intervalo dado. Compara el resultado con el método `cdf`.

Como ejemplo consideraremos la distribución gamma, cuya función de densidad está dada por

\begin{equation}
f(x, a)= \frac{x^{a-1} e^{-x}}{\Gamma (a)}
\end{equation}

Gráficamos la función de densidad con un valor de $a = 1.7$.

```{python}
#| code-fold: true
#| fig-align: 'center'

from scipy.stats import gamma
a = 1.7
x_values = np.linspace(0 , gamma.ppf(0.99, a), 500)

plt.figure(figsize=(9,5))
plt.plot(x_values, gamma.pdf(x_values, a), label="Función de densidad")
plt.grid()
plt.legend()
plt.show()
```

Elegimos el intervalo $[2,5]$ para calcular la integral.

```{python}
#| code-fold: true
#| fig-align: 'center'
a1 = 2
b1 = 5
x_values = np.linspace(0 , gamma.ppf(0.99, a), 500)

plt.figure(figsize=(9,5))
plt.plot(x_values, gamma.pdf(x_values, a), label="Función de densidad")
plt.fill_between(np.linspace(a1,b1, 500), y1=0, y2=gamma.pdf(np.linspace(a1,b1, 500), a), color="green", alpha=0.5)
plt.grid()
plt.legend()
plt.show()


```

Ahora se obtiene el valor por medio del método `cdf` (cumulative distribution function).

```{python}
gamma.cdf(3, a) - gamma.cdf(1, a)
```

